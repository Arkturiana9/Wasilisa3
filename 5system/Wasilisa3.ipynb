{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a0e2817a4604975922685662dd5b01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bffcd223b8204c78bf6ef989ddf0aadc",
              "IPY_MODEL_d8f1099f69fa4d33aa5788bb044052d2",
              "IPY_MODEL_fb1b217c7cb84d98992362188cd0ff29",
              "IPY_MODEL_13c7d2208c0847a8800a90cc93d86753",
              "IPY_MODEL_0ff96a4d2a2a4155ad54a3ee3f3cfd51",
              "IPY_MODEL_4e9bc5b1b7c845fe989fc47fd1fe74d2"
            ],
            "layout": "IPY_MODEL_9ef3df1104bd464fa12ee0633fc2f75f"
          }
        },
        "bffcd223b8204c78bf6ef989ddf0aadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb1777d20c549a99de164b62e59ba40",
            "placeholder": "​",
            "style": "IPY_MODEL_e529de6f5ffa4dbf9d51caada2a65626",
            "value": "<h2>Классификация текста</h2>"
          }
        },
        "d8f1099f69fa4d33aa5788bb044052d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229c311491a04e85a7f13e7120793dec",
            "placeholder": "​",
            "style": "IPY_MODEL_86005539e78c4fc3adef63f02a6d3fc0",
            "value": "<p>Введите текст и выберите модель для классификации.</p>"
          }
        },
        "fb1b217c7cb84d98992362188cd0ff29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Текст:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7edfb5ab271b4109bb1f564f5e8afd26",
            "placeholder": "Введите текст для классификации",
            "rows": null,
            "style": "IPY_MODEL_17c9f4ea0dcb4796963b6f65537b9961",
            "value": "Пользователи, или клиенты, могут отправлять, получать, просматривать и управлять документами через специальные приложения, которые взаимодействуют с сервером ис учёта ресурсов. Таким образом, ис учёта ресурсов обычно использует клиентсерверную архитектуру, где сервер обрабатывает запросы на поставку и хранение материалов, а клиенты работают с этой системой через свои приложения. Клиентсерверная архитектура в ис учёта ресурсов предприятия обеспечивает удобство и эффективность для пользователей. Клиенты могут использовать специализированные приложения для взаимодействия с сервером, отправлять. Сервер, в свою очередь, обеспечивает централизованное хранение данных, обработку запросов, контроль доступа и безопасность информации."
          }
        },
        "13c7d2208c0847a8800a90cc93d86753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "все модели",
              "голосование",
              "RandomForest",
              "GB",
              "kNN",
              "LogisticRegression",
              "SVC",
              "RandomForest1",
              "GB1",
              "kNN1",
              "LogisticRegression1",
              "SVC1"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Модель:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_2e0984c7c0444418bf493d2676ec9fb2",
            "style": "IPY_MODEL_e4e00a3cd514470c95878c1600303754"
          }
        },
        "0ff96a4d2a2a4155ad54a3ee3f3cfd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Классифицировать",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7e637d82790a4f2fa94a608bcc97bf2e",
            "style": "IPY_MODEL_7c3144d913cb44ad90006820bdc16228",
            "tooltip": ""
          }
        },
        "4e9bc5b1b7c845fe989fc47fd1fe74d2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_169266f6a09949bebc00f536264b3f14",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "RandomForest: Имеются признаки сгенерированного текста\n",
                  "GB: Имеются признаки сгенерированного текста\n",
                  "kNN: Имеются признаки сгенерированного текста\n",
                  "LogisticRegression: Имеются признаки сгенерированного текста\n",
                  "SVC: Имеются признаки сгенерированного текста\n",
                  "RandomForest1: Имеются признаки сгенерированного текста\n",
                  "GB1: Имеются признаки сгенерированного текста\n",
                  "kNN1: Предположительно текст написан человеком\n",
                  "LogisticRegression1: Имеются признаки сгенерированного текста\n",
                  "SVC1: Имеются признаки сгенерированного текста\n"
                ]
              }
            ]
          }
        },
        "9ef3df1104bd464fa12ee0633fc2f75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bb1777d20c549a99de164b62e59ba40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e529de6f5ffa4dbf9d51caada2a65626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "229c311491a04e85a7f13e7120793dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86005539e78c4fc3adef63f02a6d3fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7edfb5ab271b4109bb1f564f5e8afd26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "17c9f4ea0dcb4796963b6f65537b9961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e0984c7c0444418bf493d2676ec9fb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e00a3cd514470c95878c1600303754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e637d82790a4f2fa94a608bcc97bf2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3144d913cb44ad90006820bdc16228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "169266f6a09949bebc00f536264b3f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Система распознавания русскоязычного текста, сгенерированного LLM**"
      ],
      "metadata": {
        "id": "TdKJzWj62SzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Установка и загрузка библиотек и ресурсов"
      ],
      "metadata": {
        "id": "YrCC9bituDhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pymorphy2\n",
        "!pip -q install sentencepiece"
      ],
      "metadata": {
        "id": "78A4EEu0m0bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9d201b-dc86-468f-d0df-fe8056b2cbcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install spacy"
      ],
      "metadata": {
        "id": "caXt4b-mDNiI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnve7RBDTtg-",
        "outputId": "e34a57d8-96f0-47b5-ef81-c3c78fdbe26c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "n2tMUSkU_T6i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gRW_NF1SsBPq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split # делим на тестовую и тренировочную\n",
        "from sklearn.feature_extraction.text import CountVectorizer # мешок слов\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report # метрика точности, f1 мера, матрица ошибок и отчёт по классификации\n",
        "from sklearn import model_selection # выбор модели и оценка параметров (можно загрузить несколько моделей)\n",
        "from sklearn.linear_model import LogisticRegression # логистическая регрессия\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier # бустинг, случайный лес\n",
        "from sklearn.svm import SVC # метод SVM, загружаем с ядром rbf https://scikit-learn.ru/1-4-support-vector-machines/\n",
        "from sklearn.neighbors import KNeighborsClassifier # к ближайших соседей"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pymorphy2\n",
        "import re"
      ],
      "metadata": {
        "id": "CebH0zdtKKCv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import math\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "k1s-zbXyCehF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "9dVpRKF2C7LM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка необходимых ресурсов\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('ru_core_news_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV-3OMfcDDWC",
        "outputId": "e3f1ac3e-cd3c-41a5-d0e2-50e0bfb6295a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "id": "roqNOxGREqN6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Загрузка моделей\n",
        "\n",
        "**Модели обученные на TF-IDF признаках**\n",
        "\n",
        "GB_model.pkl,\n",
        "\n",
        "kNN_model.pkl,\n",
        "\n",
        "LogisticRegression_model.pkl,\n",
        "\n",
        "RandomForest_model.pkl,\n",
        "\n",
        "SVC_model.pkl\n",
        "\n",
        "vectorizer.pkl - **TF-IDF векторизатор**\n",
        "\n",
        "=========================================================\n",
        "\n",
        "**Модели обученные на новых числовых признаках**\n",
        "\n",
        "GB1_model1.pkl,\n",
        "\n",
        "kNN1_model1.pkl,\n",
        "\n",
        "LogisticRegression1_model1.pkl,\n",
        "\n",
        "RandomForest1_model1.pkl,\n",
        "\n",
        "SVC1_model1.pkl"
      ],
      "metadata": {
        "id": "ZBbgPDW-uP2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузка моделей\n",
        "!gdown 1RJ5Ig8pBgzTPiXr12HJRaNrKtaU09WtT\n",
        "!gdown 1x0vxLSmwPr4UjR_S9_o7h0l9plafmrCB\n",
        "!gdown 1ODMLAfqvTT6KNlbKurX78rFLeMXP--tn\n",
        "!gdown 1HGctCTC0xkYfsUdbtiE5PO4tYMIFJBRm\n",
        "!gdown 1_w9tpM1VSqNm5rVqV-4Awvlua1eTgEp-\n",
        "!gdown 1Ppc0L49v_i5v0MNl9esb0Ta1H695VEQW\n",
        "!gdown 1cRf6z_QMLVG9ki5YOSWQLhneNLGHXn1Q\n",
        "!gdown 14K6e9PLU3CfdSu-QRVDPRgDmcBXj3vxP\n",
        "!gdown 1qvzMkRpP-17bPCANflJQgUz_HgTtxlWB\n",
        "!gdown 1NyKrUZ1-GUiNfpj5yBHylwiAgD9f-rqG\n",
        "!gdown 1QDS8s7Xoud0zE9jhqMWD41OrqNpp9R7t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0v0mfAl9Rls",
        "outputId": "7ca12e6a-4202-4378-d58a-db896251b6d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RJ5Ig8pBgzTPiXr12HJRaNrKtaU09WtT\n",
            "To: /content/GB_model.pkl\n",
            "100% 135k/135k [00:00<00:00, 5.39MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x0vxLSmwPr4UjR_S9_o7h0l9plafmrCB\n",
            "To: /content/GB1_model1.pkl\n",
            "100% 135k/135k [00:00<00:00, 10.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ODMLAfqvTT6KNlbKurX78rFLeMXP--tn\n",
            "To: /content/kNN_model.pkl\n",
            "100% 2.63M/2.63M [00:00<00:00, 18.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HGctCTC0xkYfsUdbtiE5PO4tYMIFJBRm\n",
            "To: /content/kNN1_model1.pkl\n",
            "100% 1.33M/1.33M [00:00<00:00, 19.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_w9tpM1VSqNm5rVqV-4Awvlua1eTgEp-\n",
            "To: /content/LogisticRegression_model.pkl\n",
            "100% 122k/122k [00:00<00:00, 10.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ppc0L49v_i5v0MNl9esb0Ta1H695VEQW\n",
            "To: /content/LogisticRegression1_model1.pkl\n",
            "100% 2.83k/2.83k [00:00<00:00, 9.73MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cRf6z_QMLVG9ki5YOSWQLhneNLGHXn1Q\n",
            "To: /content/RandomForest_model.pkl\n",
            "100% 15.0M/15.0M [00:00<00:00, 105MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14K6e9PLU3CfdSu-QRVDPRgDmcBXj3vxP\n",
            "To: /content/RandomForest1_model1.pkl\n",
            "100% 11.9M/11.9M [00:00<00:00, 71.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qvzMkRpP-17bPCANflJQgUz_HgTtxlWB\n",
            "To: /content/SVC_model.pkl\n",
            "100% 2.28M/2.28M [00:00<00:00, 26.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NyKrUZ1-GUiNfpj5yBHylwiAgD9f-rqG\n",
            "To: /content/SVC1_model1.pkl\n",
            "100% 1.01M/1.01M [00:00<00:00, 34.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QDS8s7Xoud0zE9jhqMWD41OrqNpp9R7t\n",
            "To: /content/vectorizer.pkl\n",
            "100% 603k/603k [00:00<00:00, 30.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка стоп-слов и инициализация лемматизатора\n",
        "nltk.download('stopwords')\n",
        "russian_stopwords = set(stopwords.words('russian'))\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVjs-iT5KSM0",
        "outputId": "d5960f89-0740-4089-c39b-2744295fc359"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Функции очистки текста, загрузки моделей на TF-IDF признаках и векторизатора**"
      ],
      "metadata": {
        "id": "cTb0r43DyqeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для предобработки текста\n",
        "def preprocess_text(text):\n",
        "    # Приведение к нижнему регистру и удаление пунктуации\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    # Токенизация и лемматизация\n",
        "    tokens = text.split()\n",
        "    lemmatized = [morph.parse(token)[0].normal_form for token in tokens if token not in russian_stopwords]\n",
        "    return ' '.join(lemmatized)"
      ],
      "metadata": {
        "id": "E6m-laSEKinm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_models():\n",
        "    return {\n",
        "        'RandomForest': RandomForestClassifier(bootstrap=True, n_estimators=100, n_jobs=-1),\n",
        "        \"GB\": GradientBoostingClassifier(n_estimators=100),\n",
        "        \"kNN\": KNeighborsClassifier(),\n",
        "        \"LogisticRegression\": LogisticRegression(),\n",
        "        \"SVC\": SVC(kernel='rbf')\n",
        "    }\n",
        "\n",
        "\"\"\"\n",
        "# Функция для сохранения моделей и векторизатора\n",
        "def save_models(models, vectorizer):\n",
        "    for name, model in models.items():\n",
        "        with open(f'{name}_model.pkl', 'wb') as f:\n",
        "            pickle.dump(model, f)\n",
        "\n",
        "    with open('vectorizer.pkl', 'wb') as f:\n",
        "        pickle.dump(vectorizer, f)\n",
        "\"\"\"\n",
        "# Функция для загрузки моделей и векторизатора\n",
        "def load_models():\n",
        "    loaded_models = {}\n",
        "    model_names = ['RandomForest', 'GB', 'kNN', 'LogisticRegression', 'SVC']\n",
        "\n",
        "    for name in model_names:\n",
        "        with open(f'{name}_model.pkl', 'rb') as f:\n",
        "            loaded_models[name] = pickle.load(f)\n",
        "\n",
        "    with open('vectorizer.pkl', 'rb') as f:\n",
        "        vectorizer = pickle.load(f)\n",
        "\n",
        "    return loaded_models, vectorizer\n",
        "\n"
      ],
      "metadata": {
        "id": "W0OumVPmsH0y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Проверяем загрузку моделей и возможность классификации**"
      ],
      "metadata": {
        "id": "YK_opYcVyN3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования сохраненных моделей\n",
        "loaded_models, loaded_vectorizer = load_models()"
      ],
      "metadata": {
        "id": "D02b0HnZ-LWq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"Пользователи, или клиенты, могут отправлять, получать, просматривать и управлять документами через специальные приложения, которые взаимодействуют с сервером ис учёта ресурсов. Таким образом, ис учёта ресурсов обычно использует клиентсерверную архитектуру, где сервер обрабатывает запросы на поставку и хранение материалов, а клиенты работают с этой системой через свои приложения. Клиентсерверная архитектура в ис учёта ресурсов предприятия обеспечивает удобство и эффективность для пользователей. Клиенты могут использовать специализированные приложения для взаимодействия с сервером, отправлять. Сервер, в свою очередь, обеспечивает централизованное хранение данных, обработку запросов, контроль доступа и безопасность информации.\""
      ],
      "metadata": {
        "id": "LwTcznEHUXBG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_paragraph = preprocess_text(paragraph)"
      ],
      "metadata": {
        "id": "nqA-5sb4KDt5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод результата для проверки\n",
        "print(preprocessed_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEwQyENHKqgi",
        "outputId": "1d5f5cbc-28a9-4309-8861-c4713390aa08"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "пользователь клиент мочь отправлять получать просматривать управлять документ специальный приложение который взаимодействовать сервер иса учёт ресурс такой образ иса учёт ресурс обычно использовать клиентсерверный архитектура сервер обрабатывать запрос поставка хранение материал клиент работать система свой приложение клиентсерверный архитектура иса учёт ресурс предприятие обеспечивать удобство эффективность пользователь клиент мочь использовать специализировать приложение взаимодействие сервер отправлять сервер очередь обеспечивать централизовать хранение данные обработка запрос контроль доступ безопасность информация\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказание на новых данных\n",
        "new_data = [preprocessed_paragraph]\n",
        "new_data_vectorized = loaded_vectorizer.transform(new_data)"
      ],
      "metadata": {
        "id": "3sah1h3g-eMN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in loaded_models.items():\n",
        "    prediction = model.predict(new_data_vectorized)\n",
        "    print(f\"Предсказание модели {name}: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRXObJQ1-ucv",
        "outputId": "7c591633-17ce-4459-fafa-796c51edae34"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказание модели RandomForest: [1]\n",
            "Предсказание модели GB: [1]\n",
            "Предсказание модели kNN: [1]\n",
            "Предсказание модели LogisticRegression: [1]\n",
            "Предсказание модели SVC: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Конец проверки работоспособности моделей на TF-IDF признаках** ________________"
      ],
      "metadata": {
        "id": "nD9Wu3GEyQlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Работаем с моделями на новых числовых признаках"
      ],
      "metadata": {
        "id": "MHzvOHTFpXnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Функции для расчета новых числовых признаков**"
      ],
      "metadata": {
        "id": "-wQdwIqQpXOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для подсчета энтропии распределения символов\n",
        "def calculate_entropy(text):\n",
        "    freq = Counter(text)\n",
        "    entropy = 0\n",
        "    for char, count in freq.items():\n",
        "        prob = count / len(text)\n",
        "        entropy -= prob * math.log2(prob)\n",
        "    return entropy\n",
        "\n",
        "# Функция для подсчета энтропии распределения слов\n",
        "def calculate_word_entropy(tokens):\n",
        "    freq = Counter(tokens)\n",
        "    total_words = len(tokens)\n",
        "    entropy = 0\n",
        "    for word, count in freq.items():\n",
        "        prob = count / total_words\n",
        "        entropy -= prob * math.log2(prob)\n",
        "    return entropy\n",
        "\n",
        "\n",
        "# Функция для подсчета TTR\n",
        "def calculate_ttr(tokens):\n",
        "    return len(set(tokens)) / len(tokens)\n",
        "\n",
        "# Функция для подсчета индекса Хердана\n",
        "def calculate_herdan_index(tokens):\n",
        "    return math.log(len(set(tokens))) / math.log(len(tokens))\n",
        "\n",
        "\n",
        "# Функция для подсчета индекса Юла\n",
        "def calculate_yule_index(tokens):\n",
        "    freq = Counter(tokens)\n",
        "    m1 = sum(freq.values())\n",
        "    freq_of_freq = Counter(freq.values())\n",
        "    m2 = sum([f * (f - 1) * freq_of_freq[f] for f in freq_of_freq])\n",
        "    return 10000 * (m2) / (m1 * m1 - m1)\n",
        "\n",
        "\n",
        "# Функция для подсчета частоты использования служебных слов\n",
        "def calculate_function_words_ratio(tokens):\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    return sum(1 for token in tokens if token.lower() in stop_words) / len(tokens)\n",
        "\n",
        "# Функция для подсчета средней глубины синтаксического дерева\n",
        "def calculate_avg_tree_depth(doc):\n",
        "    def get_depth(token):\n",
        "        depth = 0\n",
        "        while token.head != token:\n",
        "            token = token.head\n",
        "            depth += 1\n",
        "        return depth\n",
        "\n",
        "    sentence_depths = []\n",
        "    for sent in doc.sents:\n",
        "        depths = [get_depth(token) for token in sent if token.dep_ != 'ROOT']\n",
        "        if depths:\n",
        "            sentence_depths.append(sum(depths) / len(depths))\n",
        "\n",
        "    return sum(sentence_depths) / len(sentence_depths) if sentence_depths else 0\n",
        "\n",
        "\n",
        "# Функция для подсчета соотношения частей речи\n",
        "def calculate_pos_ratio(doc):\n",
        "    pos_counts = Counter(token.pos_ for token in doc)\n",
        "    total = sum(pos_counts.values())\n",
        "    if total == 0:\n",
        "        return {}  # Возвращаем пустой словарь, если текст пустой\n",
        "\n",
        "    # Создаем словарь со всеми возможными частями речи, инициализируя их нулями\n",
        "    all_pos = {pos: 0 for pos in spacy.parts_of_speech.IDS}\n",
        "\n",
        "    # Обновляем значения для найденных частей речи\n",
        "    for pos, count in pos_counts.items():\n",
        "        all_pos[pos] = count / total\n",
        "\n",
        "    return all_pos\n",
        "\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# Функция для подсчета частоты использования падежей - почему-то не работает (!!!)\n",
        "def calculate_case_frequency(doc):\n",
        "    case_counts = Counter(token.morph.get('Case') for token in doc if 'Case' in token.morph)\n",
        "    total = sum(case_counts.values())\n",
        "    return {case: count / total for case, count in case_counts.items()}\n",
        "\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1\n",
        "# Функция для подсчета частоты биграмм и триграмм - исключила - дает слишком много малоинформативных признаков (!!!)\n",
        "def calculate_ngram_frequency(tokens, n, top_n=2):\n",
        "    ngram_counts = Counter(ngrams(tokens, n))\n",
        "    total = sum(ngram_counts.values())\n",
        "    return {f'top_{i+1}_{n}gram': ' '.join(ngram) for i, (ngram, _) in enumerate(ngram_counts.most_common(top_n))}\n",
        "\n",
        "\n",
        "# Функции для расчета индекса удобочитаемости Флеша-Кинкейда (адаптированная для русского языка)\n",
        "#функция count_syllables_ru для подсчета слогов в русских словах\n",
        "def count_syllables(word):\n",
        "    vowels = 'аеёиоуыэюя'\n",
        "    return len([char for char in word.lower() if char in vowels])\n",
        "\n",
        "def calculate_flesch_kincaid_grade(text):\n",
        "    # Очистка текста\n",
        "    text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = [word.strip('.,!?:;()[]{}') for word in word_tokenize(text) if word.strip('.,!?:;()[]{}')]\n",
        "\n",
        "    if not sentences or not words:\n",
        "        return 0\n",
        "\n",
        "    avg_sentence_length = len(words) / len(sentences)\n",
        "    avg_syllables_per_word = sum(count_syllables(word) for word in words) / len(words)\n",
        "\n",
        "    # Адаптированные коэффициенты для русского языка\n",
        "    score = 220.755 - (1.1 * avg_sentence_length) - (65.0 * avg_syllables_per_word)\n",
        "\n",
        "    # Ограничение минимального значения\n",
        "    return max(0, score)\n",
        "\n",
        "\n",
        "# Функция для расчета индекса туманности Ганнинга (адаптированная для русского языка)\n",
        "def calculate_gunning_fog_index(text):\n",
        "    if not text:\n",
        "        return 0\n",
        "\n",
        "    # Очистка текста\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    if len(sentences) == 0 or len(words) == 0:\n",
        "        return 0\n",
        "\n",
        "    complex_words = sum(1 for word in words if count_syllables(word) >= 4)\n",
        "\n",
        "    return 0.4 * ((len(words) / len(sentences)) + 100 * (complex_words / len(words)))\n",
        "\n",
        "# Функция для подсчета частоты повторения слов\n",
        "def calculate_word_repetition(tokens):\n",
        "    freq = Counter(tokens)\n",
        "    return sum(count for count in freq.values() if count > 1) / len(tokens)"
      ],
      "metadata": {
        "id": "Bgj9W4kJp32e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сам рассчет числовых признаков для датафрейма**"
      ],
      "metadata": {
        "id": "84x8LKzFriEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применение функций к датафрейму\n",
        "def extract_features(df):\n",
        "    features = []\n",
        "    for _, row in df.iterrows():\n",
        "        text = row['content']\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        sentences = sent_tokenize(text)\n",
        "        doc = nlp(text)\n",
        "\n",
        "        feature = {\n",
        "            'char_count': len(text),\n",
        "            'word_count': len(tokens),\n",
        "            'sentence_count': len(sentences),\n",
        "            'avg_word_length': sum(len(word) for word in tokens) / len(tokens),\n",
        "            'avg_sentence_length': len(tokens) / len(sentences),\n",
        "            'ttr': calculate_ttr(tokens),\n",
        "            'herdan_index': calculate_herdan_index(tokens),\n",
        "            'yule_index': calculate_yule_index(tokens),\n",
        "            'function_words_ratio': calculate_function_words_ratio(tokens),\n",
        "            'avg_punctuation_per_sentence': sum(1 for char in text if char in '.,;:!?') / len(sentences),\n",
        "            'avg_tree_depth': calculate_avg_tree_depth(doc),\n",
        "            'char_entropy': calculate_entropy(text),\n",
        "            #'word_entropy': calculate_entropy(' '.join(tokens)),\n",
        "            'word_entropy': calculate_word_entropy(tokens),\n",
        "            'flesch_kincaid_grade': calculate_flesch_kincaid_grade(text),\n",
        "            'gunning_fog_index': calculate_gunning_fog_index(text),\n",
        "            'word_repetition_frequency': calculate_word_repetition(tokens),\n",
        "        }\n",
        "\n",
        "        pos_ratio = calculate_pos_ratio(doc)\n",
        "        feature.update({f'pos_ratio_{pos}': ratio for pos, ratio in pos_ratio.items()})\n",
        "\n",
        "        case_frequency = calculate_case_frequency(doc)\n",
        "        feature.update({f'case_frequency_{case}': freq for case, freq in case_frequency.items()})\n",
        "\n",
        "        #bigram_frequency = calculate_ngram_frequency(tokens, 2)\n",
        "        #feature.update({f'bigram_frequency_{bigram}': freq for bigram, freq in bigram_frequency.items()})\n",
        "\n",
        "        #trigram_frequency = calculate_ngram_frequency(tokens, 3)\n",
        "        #feature.update({f'trigram_frequency_{trigram}': freq for trigram, freq in trigram_frequency.items()})\n",
        "\n",
        "        features.append(feature)\n",
        "\n",
        "    return pd.DataFrame(features)\n"
      ],
      "metadata": {
        "id": "82kNGq9mp7Ff"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models1():\n",
        "    return {\n",
        "        'RandomForest1': RandomForestClassifier(bootstrap=True, n_estimators=100, n_jobs=-1),\n",
        "        \"GB1\": GradientBoostingClassifier(n_estimators=100),\n",
        "        \"kNN1\": Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('knn', KNeighborsClassifier())\n",
        "        ]),\n",
        "        \"LogisticRegression1\": Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('lr', LogisticRegression())\n",
        "        ]),\n",
        "        \"SVC1\": Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('svc', SVC(kernel='rbf'))\n",
        "        ])\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Zepgh8i8uLUg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Класс для извлечения признаков\n",
        "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        # Инициализация необходимых ресурсов\n",
        "        nltk.download('punkt')\n",
        "        nltk.download('stopwords')\n",
        "        self.nlp = spacy.load('ru_core_news_sm')\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return extract_features(pd.DataFrame({'content': X}))\n",
        "\"\"\"\n",
        "# Сохранение моделей\n",
        "def save_models1(models):\n",
        "    for name, model in models.items():\n",
        "        filename = f\"{name}_model1.pkl\"\n",
        "        with open(filename, 'wb') as file:\n",
        "            pickle.dump(model, file)\n",
        "    print(\"Модели сохранены.\")\n",
        "\"\"\"\n",
        "\n",
        "# Загрузка моделей\n",
        "def load_models1():\n",
        "    loaded_models = {}\n",
        "    for name in ['RandomForest1', 'GB1', 'kNN1', 'LogisticRegression1', 'SVC1']:\n",
        "        filename = f\"{name}_model1.pkl\"\n",
        "        with open(filename, 'rb') as file:\n",
        "            loaded_models[name] = pickle.load(file)\n",
        "    print(\"Модели загружены.\")\n",
        "    return loaded_models\n",
        "\n",
        "# Функция для классификации произвольного абзаца\n",
        "def classify_paragraph(paragraph, models):\n",
        "    # Создаем DataFrame с одним абзацем\n",
        "    df = pd.DataFrame({'content': [paragraph]})\n",
        "\n",
        "    # Извлекаем признаки\n",
        "    features = extract_features(df)\n",
        "\n",
        "    # Выбираем нужные столбцы\n",
        "    selected_features = [\n",
        "        'char_count', 'word_count', 'sentence_count', 'avg_word_length',\n",
        "        'avg_sentence_length', 'ttr', 'herdan_index', 'yule_index',\n",
        "        'function_words_ratio', 'avg_punctuation_per_sentence', 'avg_tree_depth',\n",
        "        'char_entropy', 'word_entropy', 'flesch_kincaid_grade', 'gunning_fog_index',\n",
        "        'word_repetition_frequency', 'pos_ratio_ADJ', 'pos_ratio_ADP', 'pos_ratio_ADV',\n",
        "        'pos_ratio_AUX', 'pos_ratio_CCONJ', 'pos_ratio_DET', 'pos_ratio_INTJ',\n",
        "        'pos_ratio_NOUN', 'pos_ratio_NUM', 'pos_ratio_PART', 'pos_ratio_PRON',\n",
        "        'pos_ratio_PROPN', 'pos_ratio_PUNCT', 'pos_ratio_SCONJ', 'pos_ratio_SYM',\n",
        "        'pos_ratio_VERB', 'pos_ratio_X', 'pos_ratio_SPACE'\n",
        "    ]\n",
        "\n",
        "    features = features[selected_features]\n",
        "    #print(features)\n",
        "    # Классифицируем с помощью каждой модели\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        prediction = model.predict(features)\n",
        "        results[name] = prediction[0]\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "c1KCCNO5uekd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Проверяем загрузку моделей и возможность классификации**"
      ],
      "metadata": {
        "id": "wpZZMs_5sPW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "loaded_models1 = load_models1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26A3UsKUyRRd",
        "outputId": "8a45063e-bf5d-41fa-f299-4a1d17f23d07"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модели загружены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Классифицируем произвольный абзац\n",
        "sample_paragraph = \"Пользователи, или клиенты, могут отправлять, получать, просматривать и управлять документами через специальные приложения, которые взаимодействуют с сервером ис учёта ресурсов. Таким образом, ис учёта ресурсов обычно использует клиентсерверную архитектуру, где сервер обрабатывает запросы на поставку и хранение материалов, а клиенты работают с этой системой через свои приложения. Клиентсерверная архитектура в ис учёта ресурсов предприятия обеспечивает удобство и эффективность для пользователей. Клиенты могут использовать специализированные приложения для взаимодействия с сервером, отправлять. Сервер, в свою очередь, обеспечивает централизованное хранение данных, обработку запросов, контроль доступа и безопасность информации.\"\n",
        "classification_results = classify_paragraph(sample_paragraph, loaded_models1)"
      ],
      "metadata": {
        "id": "rbE9_8JOyVUz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Результаты классификации:\")\n",
        "for model_name, prediction in classification_results.items():\n",
        "    #print(f\"{model_name}: {'Позитивный' if prediction == 1 else 'Негативный'}\")\n",
        "    print(f\"{model_name}: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdSDw2yGyf5o",
        "outputId": "c8138914-ffe0-4d3d-d01a-e1172f2011da"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты классификации:\n",
            "RandomForest1: 1\n",
            "GB1: 1\n",
            "kNN1: 0\n",
            "LogisticRegression1: 1\n",
            "SVC1: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________**Конец проверки работоспособности моделей на новых признаках** ___________________________"
      ],
      "metadata": {
        "id": "gA8QJKz0sl8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Создаем интерфейс gradio для работы со всеми моделями"
      ],
      "metadata": {
        "id": "25-U-jbbtBU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio"
      ],
      "metadata": {
        "id": "ZCE3bkiH8mg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07c2319-7b74-443a-c1a6-b0fd61d8a43d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "u2PTwPhs64oU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Функции для классификации произвольного абзаца текста**"
      ],
      "metadata": {
        "id": "1dQKKBk3XB7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text(text, model_name):\n",
        "       try:\n",
        "           if model_name in loaded_models:\n",
        "               # Классификация с использованием моделей на tf-idf признаках\n",
        "               preprocessed_text = preprocess_text(text)\n",
        "               vectorized_text = loaded_vectorizer.transform([preprocessed_text])\n",
        "               prediction = loaded_models[model_name].predict(vectorized_text)\n",
        "           elif model_name in loaded_models1:\n",
        "               # Классификация с использованием моделей на новых числовых признаках\n",
        "               df = pd.DataFrame({'content': [paragraph]})\n",
        "               features = extract_features(df)\n",
        "               # Выбираем нужные столбцы\n",
        "               selected_features = [\n",
        "                   'char_count', 'word_count', 'sentence_count', 'avg_word_length',\n",
        "                   'avg_sentence_length', 'ttr', 'herdan_index', 'yule_index',\n",
        "                   'function_words_ratio', 'avg_punctuation_per_sentence', 'avg_tree_depth',\n",
        "                   'char_entropy', 'word_entropy', 'flesch_kincaid_grade', 'gunning_fog_index',\n",
        "                   'word_repetition_frequency', 'pos_ratio_ADJ', 'pos_ratio_ADP', 'pos_ratio_ADV',\n",
        "                   'pos_ratio_AUX', 'pos_ratio_CCONJ', 'pos_ratio_DET', 'pos_ratio_INTJ',\n",
        "                   'pos_ratio_NOUN', 'pos_ratio_NUM', 'pos_ratio_PART', 'pos_ratio_PRON',\n",
        "                   'pos_ratio_PROPN', 'pos_ratio_PUNCT', 'pos_ratio_SCONJ', 'pos_ratio_SYM',\n",
        "                   'pos_ratio_VERB', 'pos_ratio_X', 'pos_ratio_SPACE'\n",
        "             ]\n",
        "\n",
        "               features = features[selected_features]\n",
        "               prediction = loaded_models1[model_name].predict(features)\n",
        "           else:\n",
        "               return \"Выбрана неизвестная модель\"\n",
        "\n",
        "           return \"Имеются признаки сгенерированного текста\" if prediction[0] == 1 else \"Предположительно текст написан человеком\"\n",
        "       except Exception as e:\n",
        "           return f\"Ошибка: {str(e)}\"\n",
        "\n",
        "# Функция для классификации текста всеми моделями\n",
        "def classify_all_models(text):\n",
        "    results = {}\n",
        "    for model_name in loaded_models:\n",
        "        results[model_name] = classify_text(text, model_name)\n",
        "    for model_name in loaded_models1:\n",
        "        results[model_name] = classify_text(text, model_name)\n",
        "    return results\n",
        "\n",
        "# Функция для голосования\n",
        "def vote_classification(text):\n",
        "    all_results = classify_all_models(text)\n",
        "    votes = Counter(all_results.values())\n",
        "    return votes.most_common(1)[0][0]\n"
      ],
      "metadata": {
        "id": "jSf8JzVT6-2U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Интерфейс в gradio**"
      ],
      "metadata": {
        "id": "SfaTM-_RtzCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание интерфейса Gradio\n",
        "def gradio_interface(text, model):\n",
        "    if model == \"все модели\":\n",
        "        results = classify_all_models(text)\n",
        "        return \"\\n\".join([f\"{model}: {result}\" for model, result in results.items()])\n",
        "    elif model == \"голосование\":\n",
        "        return vote_classification(text)\n",
        "    else:\n",
        "        return classify_text(text, model)\n",
        "\n",
        "# Список доступных моделей\n",
        "models = [\"все модели\", \"голосование\"] + list(loaded_models.keys()) + list(loaded_models1.keys())\n",
        "\n",
        "# Создание интерфейса\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=5, label=\"Введите текст для классификации\"),\n",
        "        gr.Dropdown(choices=models, label=\"Выберите модель\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Результат классификации\"),\n",
        "    title=\"Классификация текста\",\n",
        "    description=\"Введите текст и выберите модель для классификации.\"\n",
        ")\n",
        "\n",
        "# Запуск интерфейса\n",
        "iface.launch(share=True)\n",
        "iface.launch(share=False, server_port=7860)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5DdEgUBC7IUV",
        "outputId": "2cdf41cf-548d-4bcf-abc5-acb2dd5e8c7f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://3702d5bd71586a3dde.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3702d5bd71586a3dde.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#На всякий случай сделаем еще интерфейс в ipywidgets. Вдруг gradio опять заглючит"
      ],
      "metadata": {
        "id": "19tz7FJ8W5SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "_wXpVjF8r7ju"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Список доступных моделей\n",
        "models = [\"все модели\", \"голосование\"] + list(loaded_models.keys()) + list(loaded_models1.keys())\n",
        "\n",
        "# Создание виджетов\n",
        "text_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Введите текст для классификации',\n",
        "    description='Текст:',\n",
        "    disabled=False,\n",
        "    layout={'width': '100%', 'height': '150px'}\n",
        ")\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=models,\n",
        "    value='все модели',\n",
        "    description='Модель:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "# Функция для обработки классификации\n",
        "def classify(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        text = text_input.value\n",
        "        model = model_dropdown.value\n",
        "\n",
        "        if model == \"все модели\":\n",
        "            results = classify_all_models(text)\n",
        "            print(\"\\n\".join([f\"{model}: {result}\" for model, result in results.items()]))\n",
        "        elif model == \"голосование\":\n",
        "            print(vote_classification(text))\n",
        "        else:\n",
        "            print(classify_text(text, model))\n",
        "\n",
        "# Создание кнопки\n",
        "classify_button = widgets.Button(description=\"Классифицировать\")\n",
        "classify_button.on_click(classify)\n",
        "\n",
        "# Создание контейнера для виджетов\n",
        "container = widgets.VBox([\n",
        "    widgets.HTML(\"<h2>Классификация текста</h2>\"),\n",
        "    widgets.HTML(\"<p>Введите текст и выберите модель для классификации.</p>\"),\n",
        "    text_input,\n",
        "    model_dropdown,\n",
        "    classify_button,\n",
        "    output\n",
        "])\n",
        "\n",
        "# Отображение интерфейса\n",
        "display(container)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521,
          "referenced_widgets": [
            "1a0e2817a4604975922685662dd5b01b",
            "bffcd223b8204c78bf6ef989ddf0aadc",
            "d8f1099f69fa4d33aa5788bb044052d2",
            "fb1b217c7cb84d98992362188cd0ff29",
            "13c7d2208c0847a8800a90cc93d86753",
            "0ff96a4d2a2a4155ad54a3ee3f3cfd51",
            "4e9bc5b1b7c845fe989fc47fd1fe74d2",
            "9ef3df1104bd464fa12ee0633fc2f75f",
            "8bb1777d20c549a99de164b62e59ba40",
            "e529de6f5ffa4dbf9d51caada2a65626",
            "229c311491a04e85a7f13e7120793dec",
            "86005539e78c4fc3adef63f02a6d3fc0",
            "7edfb5ab271b4109bb1f564f5e8afd26",
            "17c9f4ea0dcb4796963b6f65537b9961",
            "2e0984c7c0444418bf493d2676ec9fb2",
            "e4e00a3cd514470c95878c1600303754",
            "7e637d82790a4f2fa94a608bcc97bf2e",
            "7c3144d913cb44ad90006820bdc16228",
            "169266f6a09949bebc00f536264b3f14"
          ]
        },
        "id": "Ae4PVDxDr8uk",
        "outputId": "b0f1fdd9-90ae-49ae-d1f5-dd9aa70e519f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>Классификация текста</h2>'), HTML(value='<p>Введите текст и выберите модель для…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a0e2817a4604975922685662dd5b01b"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}